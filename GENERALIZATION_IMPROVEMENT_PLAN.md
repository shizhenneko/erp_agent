# 提升模型泛化能力的系统性方案

## 问题诊断

### 当前现象
模型在处理"从去年到今年涨薪幅度"问题时，错误地使用了2024-2025年，而非正确的2025-2026年。

### 根本原因分析

**这不是简单的"模仿 vs 理解"问题，而是：**

1. **信息冲突与优先级**
   - System Prompt（抽象）：去年 = 2025年
   - Example 8（具体）：比较2024-2025年
   - 结果：具体示例的影响 > 抽象规则

2. **模式匹配的"锚定效应"**
   - 问题类型相似 → 触发示例检索
   - 示例中的具体数字 → 被直接复制
   - 推理过程被"短路"

3. **Few-shot Learning的固有特性**
   - 模型会优先匹配最相似的示例
   - 具体案例比抽象规则更容易被记住
   - 这是LLM的特性，不是bug

## 改进策略矩阵

### 策略1: 抽象化示例（高优先级）⭐⭐⭐⭐⭐

**原理**: 让示例只展示"方法论"，避免可能被错误复制的具体值

#### 实施方案

**Before:**
```
问题: "哪些借阅者从2024年到2025年借书量增长最快？"
SQL: WHERE EXTRACT(YEAR FROM loan_date) = 2024
```

**After (方案A - 占位符):**
```
问题: "哪些借阅者从去年到今年借书量增长最快？"
Thought: "当前年份是{year}年，去年={year-1}，今年={year}"
SQL: WHERE EXTRACT(YEAR FROM loan_date) = {year-1}
```

**After (方案B - 元变量):**
```
问题: "比较YEAR_A和YEAR_B的变化"
强调: YEAR_A和YEAR_B是示例变量，实际使用时根据问题重新计算
```

#### 优点
- ✅ 强制模型每次重新推理时间
- ✅ 避免具体数字的"锚定效应"
- ✅ 教授方法而非答案

#### 实施难度
- 中等（需要重写部分示例）

---

### 策略2: 精简示例数量（高优先级）⭐⭐⭐⭐

**原理**: "少即是多" - 只保留最核心、最通用的推理模式

#### 当前问题
- 10个示例，每个都很具体
- 容易导致"过拟合"到示例场景
- Token消耗大，注意力分散

#### 改进方案

**保留的核心示例（建议5-6个）：**
1. ✅ **基础查询** - 单表统计
2. ✅ **时间推理** - 相对日期计算（抽象化！）
3. ✅ **多表关联** - JOIN技术
4. ✅ **跨期对比** - CTE模式（抽象化！）
5. ✅ **数据完整性检测** - generate_series模式
6. ✅ **复杂聚合** - GROUP BY + HAVING

**删除或合并：**
- ❌ 过于简单的示例（可以通过system prompt说明）
- ❌ 与其他示例重复的技术点
- ❌ 过于特定场景的示例

#### 优点
- ✅ 减少"模式过拟合"
- ✅ 提高推理灵活性
- ✅ 节省Token，提高响应速度

---

### 策略3: 增强System Prompt的权威性（中优先级）⭐⭐⭐⭐

**原理**: 在架构层面强调"规则优先于示例"

#### 实施方案

**1. 添加元认知提示：**
```markdown
## ⚠️ 关键原则（必须遵守）

**示例仅用于教学，不得直接复制！**

面对新问题时：
1. 首先：根据当前时间（{year}年）重新计算相对日期
2. 然后：根据实际Schema（非示例中的虚构表）构建SQL
3. 最后：参考示例中的"推理方法"，而非"具体SQL"

**特别提醒 - 时间处理：**
- ❌ 错误：看到示例中用2024年，就在实际SQL中也用2024年
- ✅ 正确：看到示例教的是"去年=当前年-1"，根据当前年份{year}重新计算
```

**2. 在示例前添加警告：**
```markdown
---
⚠️ 以下示例仅为教学演示，使用虚构场景和示例年份
⚠️ 实际查询时必须：(1) 使用真实Schema (2) 重新计算时间
---
```

---

### 策略4: Chain-of-Thought强化（中优先级）⭐⭐⭐

**原理**: 强制模型展示完整推理链，防止"跳步"

#### 实施方案

**修改输出格式要求：**
```json
{
  "thought": "必须包含以下推理步骤：
    1. 问题分析：这是什么类型的查询？
    2. 时间推理：如果涉及相对时间，明确计算（当前年份→去年/今年）
    3. 表结构分析：需要哪些表和字段？
    4. 技术选择：使用什么SQL技术（JOIN/CTE/窗口函数）？
    5. 预期结果：这个SQL应该返回什么？",
  "action": "execute_sql",
  "sql": "..."
}
```

**在system prompt中要求：**
```markdown
### Thought字段要求（必须遵守）

你的thought必须明确展示：
- ✅ "当前年份是{year}，去年={year-1}，因此查询2025年数据"
- ❌ "查询去年数据"（不明确）

这样可以：
1. 防止思维"短路"
2. 便于调试错误
3. 提高推理透明度
```

---

### 策略5: 负样本学习（低优先级）⭐⭐

**原理**: 展示"错误案例"，让模型学会避免

#### 实施方案

**添加反例示例：**
```markdown
## ❌ 错误示例：被示例锚定

**问题**: "从去年到今年的销售额变化？"（当前是2026年）

**错误推理**:
{
  "thought": "参考示例8，使用2024和2025年",
  "sql": "WHERE year IN (2024, 2025)"  ❌ 错误！
}

**问题**: 没有根据当前时间重新计算，直接复制了示例中的年份

**正确推理**:
{
  "thought": "当前是2026年，去年=2025，今年=2026，因此比较这两年",
  "sql": "WHERE year IN (2025, 2026)"  ✅ 正确！
}
```

---

### 策略6: 使用更强的基础模型（终极方案）⭐⭐⭐⭐⭐

**现实分析**: 

| 模型能力层级 | Few-shot依赖度 | 泛化能力 | 建议策略 |
|------------|--------------|---------|---------|
| GPT-3.5 / Claude 2 | 高 | 中等 | 必须精心设计prompt |
| GPT-4 / Claude 3 | 中 | 良好 | 可以使用更少示例 |
| Claude 3.5 Sonnet / GPT-4 Turbo | 低 | 优秀 | Zero-shot也可能work |

**当前使用的模型**: 
```python
# 检查你的配置
llm_config.model  # 是什么模型？
```

**建议**:
- 如果使用较弱模型：优先执行策略1-4
- 如果可以升级模型：考虑升级到Claude 3.5 Sonnet或GPT-4

---

## 实施优先级路线图

### 阶段1: 快速修复（1-2小时）
1. ✅ [已完成] 修正示例8的具体年份
2. ✅ [已完成] 加强system prompt中的时间说明
3. 🔲 在examples.txt开头添加元认知警告
4. 🔲 在system prompt中添加"思维链"要求

### 阶段2: 中期优化（3-4小时）
1. 🔲 抽象化所有时间相关示例
2. 🔲 精简示例从10个到6个
3. 🔲 为每个示例添加"学习要点"注释
4. 🔲 测试并验证改进效果

### 阶段3: 深度重构（1-2天）
1. 🔲 重新设计examples结构：
   - 第一部分：核心技术模式库（不含具体问题）
   - 第二部分：推理方法示例（抽象化场景）
2. 🔲 实施负样本学习
3. 🔲 如果效果仍不理想，考虑升级基础模型

---

## 验证方案

### 测试用例设计

创建一组"泛化能力测试"：

```python
# test_generalization.py

test_cases = [
    {
        "name": "时间推理 - 相对年份",
        "question": "从去年到今年的薪资涨幅前10名？",
        "expected_years": [2025, 2026],  # 当前是2026年
        "should_not_use": [2024]  # 不应该用示例中的年份
    },
    {
        "name": "时间推理 - 前年",
        "question": "前年第二季度的收入？",
        "expected_range": ["2024-04-01", "2024-06-30"],
        "should_not_use": ["2023"]
    },
    {
        "name": "新场景 - 示例中未出现的模式",
        "question": "哪些部门的平均工作年限超过5年？",
        "required_logic": ["AVG", "DATE_DIFF", "GROUP BY"],
        "should_not_copy_from": "any_example"
    }
]
```

### 评估指标

1. **时间准确率**: 是否使用了正确的年份/时间范围
2. **Schema准确率**: 是否使用了实际表名（而非示例中的虚构表）
3. **技术迁移能力**: 能否在新场景中应用示例教的技术
4. **思维链完整性**: thought中是否明确展示了推理过程

---

## 理论基础：为什么这些策略有效？

### 1. 认知科学角度

**问题**: LLM的"系统1思维"（快速模式匹配）vs "系统2思维"（深度推理）

**解决**: 
- 抽象化示例 → 破坏直接模式匹配
- Chain-of-Thought → 激活系统2思维
- 元认知提示 → 提高"自我监控"

### 2. 机器学习角度

**过拟合三要素**:
1. 训练数据（示例）过于具体
2. 模型容量相对较小
3. 缺乏正则化机制

**对应策略**:
1. 策略1（抽象化）→ 减少过拟合
2. 策略6（更强模型）→ 提高容量
3. 策略3（元认知）→ 相当于"正则化"

### 3. Prompt Engineering最佳实践

```
优先级: System Prompt > Few-shot Examples > Task Description

当前问题: Examples影响力 > System Prompt

解决方案: 
1. 提升System Prompt权威性（策略3）
2. 降低Examples具体性（策略1）
3. 减少Examples数量（策略2）
```

---

## 结论

**问题本质**: 不是模型"只会模仿"，而是在信息冲突时的优先级选择问题

**核心洞察**: 
- ✅ 模型有泛化能力（其他问题都对了）
- ⚠️ 具体示例的"锚定效应"超出预期
- 🎯  需要调整prompt架构，而非责怪模型

**推荐方案（按优先级）**:
1. **立即执行**: 抽象化时间相关示例（策略1）
2. **本周完成**: 精简示例数量（策略2）
3. **持续优化**: 增强思维链要求（策略4）
4. **长期考虑**: 评估模型升级（策略6）

**预期效果**:
- 短期（阶段1）：修复当前时间推理问题
- 中期（阶段2）：提升整体泛化能力20-30%
- 长期（阶段3）：建立稳健的推理框架
